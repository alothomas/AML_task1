{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre import imputation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = pd.read_csv('Data/X_train.csv')\n",
    "df_y_train = pd.read_csv('Data/y_train.csv')\n",
    "df_test = pd.read_csv('Data/X_test.csv')\n",
    "df_train_id = df_x_train['id']\n",
    "df_test_id = df_test['id'].copy()\n",
    "\n",
    "df_train = pd.merge(df_x_train, df_y_train, on='id')\n",
    "\n",
    "df_train = df_train.drop(\"id\", axis=1) #we don't need id column for training set, only for final testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation of values\n",
    "\n",
    "estimator_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1\n",
    "    # Add other XGBoost parameters here\n",
    "}\n",
    "\n",
    "mice_params = {\n",
    "    'max_iter': 10,\n",
    "    'imputation_order': 'descending'\n",
    "    # Add other MICE parameters here\n",
    "}\n",
    "\n",
    "# Call the function with the additional parameters\n",
    "df_train_imputed = imputation.impute_data_with_mice_V2(\n",
    "    df_train.drop(columns=['y']),\n",
    "    estimator_params=estimator_params,\n",
    "    mice_params=mice_params\n",
    ")\n",
    "df_train_imputed = pd.concat([df_train_imputed, df_train['y']], axis=1)\n",
    "\n",
    "df_test_imputed = imputation.impute_data_with_mice_V2(\n",
    "    df_test.drop(columns=[\"id\"]),\n",
    "    estimator_params=estimator_params,\n",
    "    mice_params=mice_params\n",
    ")\n",
    "\n",
    "df_test_imputed = pd.concat([df_test_imputed, df_test['id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_imputed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alois\\Desktop\\Advanced ML\\AML_Task_1\\task1\\modeling.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/AML_Task_1/task1/modeling.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpre\u001b[39;00m \u001b[39mimport\u001b[39;00m outliers_detection\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/AML_Task_1/task1/modeling.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m columns_to_exclude \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/AML_Task_1/task1/modeling.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m feature_columns \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df_train_imputed\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m columns_to_exclude]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/AML_Task_1/task1/modeling.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m input_mat \u001b[39m=\u001b[39m df_train_imputed[feature_columns]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alois/Desktop/Advanced%20ML/AML_Task_1/task1/modeling.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m processed_data \u001b[39m=\u001b[39m outliers_detection\u001b[39m.\u001b[39moutliers_z_score(input_mat)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train_imputed' is not defined"
     ]
    }
   ],
   "source": [
    "# Outlier removal\n",
    "from pre import outliers_detection\n",
    "columns_to_exclude = ['y']\n",
    "\n",
    "feature_columns = [col for col in df_train_imputed.columns if col not in columns_to_exclude]\n",
    "input_mat = df_train_imputed[feature_columns].values\n",
    "\n",
    "processed_data = outliers_detection.outliers_z_score(input_mat)\n",
    "\n",
    "df_train_outlier = pd.DataFrame(processed_data, columns=feature_columns)\n",
    "\n",
    "for col in columns_to_exclude:\n",
    "    df_train_outlier[col] = df_train_imputed[col]\n",
    "\n",
    "\n",
    "\n",
    "input_mat_test = df_test_imputed.drop(columns=['id']).values\n",
    "processed_data_test = outliers_detection.outliers_z_score(input_mat_test)\n",
    "\n",
    "df_test_outlier = pd.DataFrame(processed_data_test, columns=feature_columns)\n",
    "\n",
    "df_test_outlier = pd.concat([df_test_outlier, df_test_imputed['id']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "X = df_train_outlier.drop(columns=['y'])  # Extract features\n",
    "y = df_train_outlier['y']  # Extract the target\n",
    "\n",
    "k = 5  # Change this to the desired number of features\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "selected_features_df = pd.DataFrame(X_new, columns=X.columns[selected_indices])\n",
    "selected_features_df_test = df_test_imputed.iloc[:, selected_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.concat([selected_features_df, df_train_outlier['y']], axis=1)\n",
    "df_test_processed = pd.concat([selected_features_df_test, df_test_imputed['id']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If no feature selection\n",
    "\n",
    "df_processed = df_train_imputed\n",
    "df_test_processed = df_test_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_processed.drop(columns=['y']), df_processed['y'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x458    2.007553\n",
      "x141    1.841784\n",
      "x89     1.449619\n",
      "x194   -1.407826\n",
      "x350    1.302523\n",
      "          ...   \n",
      "x111    0.000000\n",
      "x112   -0.000000\n",
      "x116   -0.000000\n",
      "x120    0.000000\n",
      "x252   -0.000000\n",
      "Length: 832, dtype: float64\n",
      "Number of important features:  347\n",
      "R^2 Score on Test Set: 0.34\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Construct pipeline & fit model\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(alpha=0.1, fit_intercept=True))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Print coefficients\n",
    "lasso_coef = pd.Series(pipe.named_steps['lasso'].coef_)\n",
    "lasso_coef.index = pd.Index(X_train.columns)\n",
    "print(lasso_coef.sort_values(ascending=False, key=abs))\n",
    "\n",
    "# Important features\n",
    "important_features = lasso_coef[lasso_coef != 0].index\n",
    "print('Number of important features: ', important_features.shape[0])\n",
    "\n",
    "# Calculate R2 score on test split\n",
    "pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, pred)\n",
    "print(f'R^2 Score on Test Set: {r2:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alois\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e+01, tolerance: 9.053e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\alois\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.730e+01, tolerance: 9.215e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\alois\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.887e+01, tolerance: 9.159e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation R^2 Scores: [0.30723969 0.24803328 0.36113586 0.29245828 0.22079943]\n",
      "Mean R^2 Score: 0.29\n",
      "Standard Deviation of R^2 Scores: 0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define features and target\n",
    "X = df_processed.drop(columns=['y'])\n",
    "y = df_processed['y']\n",
    "\n",
    "# Construct the pipeline & Lasso model\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(alpha=0.1, fit_intercept=True))\n",
    "])\n",
    "\n",
    "# Perform cross-validation (e.g., 5-fold cross-validation)\n",
    "cv_scores = cross_val_score(pipe, X, y, cv=5, scoring='r2')\n",
    "best_model = pipe.fit(X, y)  # Train the best model on the entire training data\n",
    "print('Cross-Validation R^2 Scores:', cv_scores)\n",
    "\n",
    "# Calculate the mean and standard deviation of the R^2 scores\n",
    "mean_r2 = cv_scores.mean()\n",
    "std_r2 = cv_scores.std()\n",
    "\n",
    "print(f'Mean R^2 Score: {mean_r2:.2f}')\n",
    "print(f'Standard Deviation of R^2 Scores: {std_r2:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "X_test = df_test_processed.drop('id', axis=1).astype(float)  # Ensure data type is float\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test_processed['id'], 'y': predictions})\n",
    "submission.to_csv('submissionLinReg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation R^2 Scores: [0.35661827 0.31213773 0.40096122 0.35778794 0.22811881]\n",
      "Mean R^2 Score: 0.33\n",
      "Standard Deviation of R^2 Scores: 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "# Define features and target\n",
    "X = df_processed.drop(columns=['y'])\n",
    "y = df_processed['y']\n",
    "\n",
    "# Create a pipeline with a Lasso model and a scaler\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso())\n",
    "])\n",
    "\n",
    "# Define a grid of alpha values to search\n",
    "param_grid = {\n",
    "    'lasso__alpha': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the data to find the best hyperparameters\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best model with the tuned hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation with the best model\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='r2')\n",
    "print('Cross-Validation R^2 Scores:', cv_scores)\n",
    "\n",
    "# Calculate the mean and standard deviation of the R^2 scores\n",
    "mean_r2 = cv_scores.mean()\n",
    "std_r2 = cv_scores.std()\n",
    "print(f'Mean R^2 Score: {mean_r2:.2f}')\n",
    "print(f'Standard Deviation of R^2 Scores: {std_r2:.2f}')\n",
    "\n",
    "# Use the best model to make predictions on the test data\n",
    "X_test = df_test_processed.drop('id', axis=1).astype(float)  # Ensure data type is float\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({'id': df_test_processed['id'], 'y': predictions})\n",
    "submission.to_csv('submissionLinReg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Real test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(df_test_processed.drop('id', axis=1))\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test_processed['id'], 'y': predictions})\n",
    "submission.to_csv('submissionLinReg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
